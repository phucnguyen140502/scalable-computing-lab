# -*- coding: utf-8 -*-
"""Lab4_Nguyễn_Đức_Nguyên_Phúc.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k0CgZeZYViW6A0bmiXPzZTnHm6LcNzmx

## Exercise 1
Write a function to compute the below formualation with the use of map function
\begin{equation}
x^2 + y^2 - r^2
\end{equation}

then, print out the values of the equation at these below values of $x$, $y$ and $z$
```
x = [1,2,3,4,5,6]
y = [2,3,4,5,6,7]
r = [1,1,3,3,4,5]

```
"""

import math

def compute_equation(x, y, r):
    return x**2 + y**2 - r**2

x = [1,2,3,4,5,6]
y = [2,3,4,5,6,7]
r = [1,1,3,3,4,5]

results = list(map(compute_equation, x, y, r))
results

"""## Exercise 2

Write a function that take input as a list of words and return to a list of integers representing the lengths of the correponding words.

Write it in three different ways:
1. using a for-loop,
2. using function `map()`, and
3. using list comprehensions.
"""

def word_lengths_for(words):
    lengths = []
    for word in words:
        lengths.append(len(word))
    return lengths

def word_lengths_map(words):
    return list(map(len, words))

def word_lengths_comprehension(words):
    return [len(word) for word in words]

"""## Exercise 3

Implement a program to make a list whose elements are double string of a string `re` (i.e., `rere`), where `re` is the first two characters of approriate elements in this list:

`['real', 'rock', 'realize', 'rocket', 'red', 'eraser' , '7', 8 , 9, 10]`.
"""

def double_string(words):
    double_strings = []
    for word in words:
        if isinstance(word, str) and len(word) >= 2:
            re = word[:2]
            double_strings.append(re * 2)
    return double_strings

words = ['real', 'rock', 'realize', 'rocket', 'red', 'eraser', '7', 8, 9, 10]
result_list = double_string(words)
result_list

"""## Exercise 4

Write a function `max_in_list()` that takes a list of numbers and returns the largest one using `reduce()` in lib `functools`
"""

from functools import reduce

def max_in_list(numbers):
    return reduce(lambda x, y: x if x > y else y, numbers)

"""## Exercise 5

Using Python `map` to write a Python program to triple all numbers of a given list of integers.
"""

def triple_numbers(numbers):
    return list(map(lambda x: x * 3, numbers))

"""## Exercise 6
Implement parallel processing using `map()` to apply a function across multiple elements of an iterable concurrently, and then use `reduce()` to aggregate the results.
"""

from concurrent.futures import ThreadPoolExecutor  # Để thực hiện song song
from functools import reduce  # Để tích lũy kết quả

# Hàm tính bình phương
def square(x):
    return x * x

# Danh sách số đầu vào
numbers = [1, 2, 3, 4, 5]

# 1. Song song với ThreadPoolExecutor.map()
with ThreadPoolExecutor() as executor:
    # Áp dụng hàm square() song song
    results = list(executor.map(square, numbers))  # [1, 4, 9, 16, 25]

print("Squared results:", results)

# 2. Tích lũy với reduce()
total_sum = reduce(lambda x, y: x + y, results)  # Tính tổng các bình phương
print("Sum of squares:", total_sum)

"""## Exercise 7
Implement a MapReduce-style function to process data distributed across multiple nodes or workers.
"""

## bài toán cơ bản nhất của bigdata nếu từ xuất hiện

from collections import defaultdict
from functools import reduce
from concurrent.futures import ThreadPoolExecutor

# Hàm Map: Đếm số lần xuất hiện của từng từ trong một phần dữ liệu
def map_function(data_chunk):
    word_count = {}  # Tạo một dictionary để lưu số lần xuất hiện của từ
    for word in data_chunk:
        word_count[word] = word_count.get(word, 0) + 1  # Tăng số lần xuất hiện của từ
    return word_count

# Hàm Reduce: Gộp kết quả từ nhiều worker
def reduce_function(mapped_data):
    final_count = {}
    for partial_result in mapped_data:
        for word, count in partial_result.items():
            final_count[word] = final_count.get(word, 0) + count  # Gộp số lần xuất hiện
    return final_count

# Hàm chính để thực hiện MapReduce
def mapreduce(data, num_workers=4):
    # 1. Chia dữ liệu thành nhiều phần nhỏ để phân phối cho các worker
    chunk_size = len(data) // num_workers
    data_chunks = [data[i:i + chunk_size] for i in range(0, len(data), chunk_size)]

    # 2. Thực hiện giai đoạn Map song song với các worker
    with ThreadPoolExecutor(max_workers=num_workers) as executor:
        mapped_results = list(executor.map(map_function, data_chunks))

    # 3. Thực hiện giai đoạn Reduce để gộp kết quả
    final_result = reduce_function(mapped_results)

    return final_result

# Dữ liệu mẫu
data = [
    "hadoop", "spark", "hadoop", "mapreduce",
    "spark", "hive", "spark", "hadoop",
    "hive", "hive", "mapreduce", "spark"
]

# Gọi hàm MapReduce
result = mapreduce(data, num_workers=3)

# Kết quả
print("Kết quả đếm từ:", result)